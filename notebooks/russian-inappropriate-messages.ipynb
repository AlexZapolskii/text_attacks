{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "cellId": "qrckypn014xiywkv4al6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "2e60467d-6a6b-4898-e2f4-f42884cc6092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x6qbstw9pgas2lqs5np1fh"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "wxcm6vmcjqsnipymls1jl9"
   },
   "source": [
    "Датасет русских новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "cellId": "cjtovd92aum7wl7t0iihh2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "cellId": "fksspqp907t496byc7kpl9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "train_df = pd.read_csv('../data/inappropriate/train.csv')\n",
    "test_df = pd.read_csv('../data/inappropriate/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "cellId": "xxbpdsycfgphxhamz1a3t9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130665, 21), (16334, 22))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "cellId": "sla5mmhslxov0mcfqiaknd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>inappropriate</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>...</th>\n",
       "      <th>weapons</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "      <th>human_labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я думал что левиафаны - это те медленные страх...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>А был бы этот полицейский в Петербурге, так пе...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Напоминаю, что пора искать актис невзрослого п...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>курю лет пятнадцать никаких проблем кроме како...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>окей, я тогда проведу парад гетеросексуалов, п...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  inappropriate  \\\n",
       "0  я думал что левиафаны - это те медленные страх...           1.00   \n",
       "1  А был бы этот полицейский в Петербурге, так пе...           0.95   \n",
       "2  Напоминаю, что пора искать актис невзрослого п...           1.00   \n",
       "3  курю лет пятнадцать никаких проблем кроме како...           1.00   \n",
       "4  окей, я тогда проведу парад гетеросексуалов, п...           1.00   \n",
       "\n",
       "   offline_crime  online_crime  drugs  gambling  pornography  prostitution  \\\n",
       "0            0.0           0.0    0.0       0.0          0.0           0.0   \n",
       "1            0.0           0.0    0.0       0.0          0.0           1.0   \n",
       "2            0.0           0.0    0.0       0.0          0.0           0.0   \n",
       "3            0.0           0.0    1.0       0.0          0.0           0.0   \n",
       "4            0.0           0.0    0.0       0.0          0.0           0.0   \n",
       "\n",
       "   slavery  suicide  ...  weapons  body_shaming  health_shaming  politics  \\\n",
       "0      0.0      0.0  ...      0.0           0.0             0.0       0.0   \n",
       "1      0.0      0.0  ...      0.0           0.0             0.0       0.0   \n",
       "2      0.0      0.0  ...      0.0           0.0             0.0       0.0   \n",
       "3      0.0      0.0  ...      0.0           0.0             0.0       0.0   \n",
       "4      0.0      0.0  ...      0.0           0.0             0.0       0.0   \n",
       "\n",
       "   racism  religion  sexual_minorities  sexism  social_injustice  \\\n",
       "0     0.0       0.0                0.0     0.0               0.0   \n",
       "1     0.0       0.0                0.0     0.0               0.0   \n",
       "2     0.0       0.0                1.0     0.0               0.0   \n",
       "3     0.0       0.0                0.0     0.0               0.0   \n",
       "4     0.0       0.0                1.0     0.0               0.0   \n",
       "\n",
       "   human_labeled  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "cellId": "d0403c5f0jankvpgos3oz9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    91803\n",
       "1    38862\n",
       "Name: inappropriate, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "(train_df.inappropriate > 0.5).astype('int').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "cellId": "8br3c1v0hsstgm4cg2newg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    130665.000000\n",
       "mean         16.149834\n",
       "std          11.963462\n",
       "min           1.000000\n",
       "25%           9.000000\n",
       "50%          13.000000\n",
       "75%          21.000000\n",
       "max         738.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# statistics of text length (in words)\n",
    "train_df['text'].apply(lambda s: len(s.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "2zvswbwp7b6e2ddkfhdgx7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_df['text'].apply(lambda s: len(s.split())).quantile(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ojyoxtdlnfknganup05c",
    "id": "4SMZ5T5Imhlx"
   },
   "source": [
    "\n",
    "\n",
    "Let's extract the sentences and labels of our training set as numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "cellId": "m34oe1hw05p1dhexpqhi1c",
    "id": "GuE5BqICAne2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Get the lists of sentences and their labels.\n",
    "sentences = train_df.text.values\n",
    "labels = (train_df.inappropriate > 0.5).astype('int').values\n",
    "\n",
    "#valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "n2m4dcnkfdaicq7fwl9c6o",
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "# 3. Tokenization & Input Formatting\n",
    "\n",
    "In this section, we'll transform our dataset into the format that BERT can be trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qtzfq4mx3uw401xg02zbn",
    "id": "-8kEDRvShcU5"
   },
   "source": [
    "## 3.1. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nltqt9p18y4hwrqoid46m",
    "id": "bWOPOyWghJp2"
   },
   "source": [
    "\n",
    "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
    "\n",
    "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "y9el2fkaw5shwqmo17kumb"
   },
   "outputs": [],
   "source": [
    "На этот раз, используем русскоязычный Берт от Дип Павлова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "cellId": "6jmucnexl0vfmaq78346gl",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "82ddfcea0e4c4e5a86cf6eca8585be8d",
      "8a256ba4a19e4ec98fe3c3c99fba4daa",
      "8c76faadf2f4415393c6f0a805f0d72b",
      "e0bb735fda99434a90380e7fc664212d",
      "cdb78e75309f4bc09366533331e72431",
      "1058e0b5baa248faa60c1ad146d10bf7",
      "375cc635389c4ddb9bf2aa443df58bae",
      "472198d5b6a748b3a81f9364fd1fa711"
     ]
    },
    "id": "Z474sSC6oe7A",
    "outputId": "4e6d97b6-2d4c-42ca-c201-d2b4a88895b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c6fa357b104a2c8a8a79ba4eb8224b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f84cddc4348628575e2129eb34937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe55da933f3444092eac2f6805b7941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=24.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b01bded5974be98abbccdfa35b47f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "cellId": "csrt6hf3abf07y5zxj7xnfq",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "82ddfcea0e4c4e5a86cf6eca8585be8d",
      "8a256ba4a19e4ec98fe3c3c99fba4daa",
      "8c76faadf2f4415393c6f0a805f0d72b",
      "e0bb735fda99434a90380e7fc664212d",
      "cdb78e75309f4bc09366533331e72431",
      "1058e0b5baa248faa60c1ad146d10bf7",
      "375cc635389c4ddb9bf2aa443df58bae",
      "472198d5b6a748b3a81f9364fd1fa711"
     ]
    },
    "id": "Z474sSC6oe7A",
    "outputId": "4e6d97b6-2d4c-42ca-c201-d2b4a88895b9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e062a6c7c28b4f74816db055c7e560a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=132977.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b1faa4ec414840a56f21176f1df2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=49.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49d56cad9b14366a1fdc27ec2b3a14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=659.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# сравним с мультиязычной моделью\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('Geotrend/bert-base-ru-cased', do_lower_case=True)  #мультиязычная, но только с русским словарем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "f6ic2xeksek12tly7v2t7yh",
    "id": "dFzmtleW6KmJ"
   },
   "source": [
    "Let's apply the tokenizer to one sentence just to see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "cellId": "mny8uy4m80cjfn7q4gsbjj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLIbudgfh6F0",
    "outputId": "9ca681ff-195f-4960-a0ba-55ded440278e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Я уже написал как я понимаю принцип око за око. Соотносится ли он с заповедями какой либо религии мне все равно. Я не верю ни в одну существующую религию ибо они все лгут и преследуют свои цели)\n",
      "Tokenized:  ['я', 'уже', 'написал', 'как', 'я', 'понимаю', 'принцип', 'око', 'за', 'око', '.', 'соотносится', 'ли', 'он', 'с', 'заповед', '##ями', 'как', '##ои', 'либо', 'религии', 'мне', 'все', 'равно', '.', 'я', 'не', 'верю', 'ни', 'в', 'одну', 'существующую', 'религию', 'ибо', 'они', 'все', 'л', '##гут', 'и', 'преследуют', 'свои', 'цели', ')']\n",
      "Token IDs:  [877, 4745, 12715, 2739, 877, 65339, 12058, 19304, 1758, 19304, 132, 105013, 11089, 2886, 869, 19517, 8037, 2739, 15484, 8568, 23539, 16740, 4752, 17561, 132, 877, 1699, 77523, 7036, 845, 12742, 87631, 54405, 32971, 4725, 4752, 863, 46269, 851, 62784, 8305, 16934, 122]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[1000])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[1000]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hs1qhwb66gl3w0a5ve8ao2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "сравним "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "cellId": "3b4lddezer765urlbbrxua",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLIbudgfh6F0",
    "outputId": "9ca681ff-195f-4960-a0ba-55ded440278e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Я уже написал как я понимаю принцип око за око. Соотносится ли он с заповедями какой либо религии мне все равно. Я не верю ни в одну существующую религию ибо они все лгут и преследуют свои цели)\n",
      "Tokenized:  ['я', 'уже', 'написал', 'как', 'я', 'по', '##нима', '##ю', 'принцип', 'око', 'за', 'око', '.', 'со', '##от', '##нос', '##ится', 'ли', 'он', 'с', 'за', '##пов', '##ед', '##ями', 'како', '##и', 'либо', 'религии', 'мне', 'все', 'равно', '.', 'я', 'не', 'в', '##ер', '##ю', 'ни', 'в', 'одну', 'су', '##ществ', '##ую', '##щую', 'р', '##ели', '##ги', '##ю', 'и', '##бо', 'они', 'все', 'л', '##гу', '##т', 'и', 'пре', '##след', '##уют', 'свои', 'цели', ')']\n",
      "Token IDs:  [194, 2177, 6886, 707, 194, 369, 12923, 533, 9679, 2848, 320, 2848, 27, 710, 735, 10908, 6727, 5058, 759, 182, 320, 6527, 4856, 3303, 1419, 288, 3651, 12782, 9527, 1729, 14141, 27, 194, 424, 167, 1178, 533, 2986, 167, 4876, 531, 12362, 1974, 7799, 181, 2766, 1851, 533, 173, 4544, 1887, 1729, 176, 2175, 408, 173, 5859, 10321, 6569, 3405, 7058, 22]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[1000])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[1000]))\n",
    "\n",
    "# Print the sentence mapped to token ids.и\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9sxllh2wshm2d0jljgysgu"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "сразу видна разница в токенизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "f0bzhx87zoslojylqdjd",
    "id": "l6w8elb-58GJ"
   },
   "source": [
    "## 3.3. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pa70o6ujlergqrti32dqxq",
    "id": "U28qy4P-NwQ9"
   },
   "source": [
    "The transformers library provides a helpful `encode` function which will handle most of the parsing and data prep steps for us.\n",
    "\n",
    "Before we are ready to encode our text, though, we need to decide on a **maximum sentence length** for padding / truncating to.\n",
    "\n",
    "The below cell will perform one tokenization pass of the dataset in order to measure the maximum sentence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellId": "xlo28mhoywpnguhvgxvoi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKsH2sU0OCQA",
    "outputId": "e363e816-c750-422f-b623-dce428f77502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  1115\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1eqbtipj60j0eqdvu6e8xxw",
    "id": "1M296yz577fV"
   },
   "source": [
    "Just in case there are some longer test sentences, I'll set the maximum length to 64.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "i755qyr606mma331z1j2bj",
    "id": "tIWAoWL2RK1p"
   },
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
    "\n",
    "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cellId": "c5cwrgpszatopts1i3ar5m"
   },
   "outputs": [],
   "source": [
    "По хорошему - нужно посмотреть на распределение длины последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "cellId": "yytmmzbcb1zzlhqavefsg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bBdb3pt8LuQ",
    "outputId": "b4d78c6d-0faf-459b-b11a-a26ce40bd32a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  я думал что левиафаны - это те медленные страхоебины с NUMBER вебмки\n",
      "Token IDs: tensor([  101,   877, 48241,  1997, 10208, 17116, 51988,   880,   130,  3998,\n",
      "         4922, 62570,  2059, 14626,  2325, 11907,   880,   869, 22948, 12724,\n",
      "        23663,   866,  2237,   102,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.  # возьмем максимальную длину последовательности\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "82676h6h03u8rs5mvnowla",
    "id": "aRp4O7D295d_"
   },
   "source": [
    "## 3.4. Training & Validation Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "iuprzz80qrdsfz1b97rtk",
    "id": "qu0ao7p8rb06"
   },
   "source": [
    "Divide up our training set to use 90% for training and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "cellId": "ib4pjswxwwzpdbvvlplze",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEgLpFVlo1Z-",
    "outputId": "c0ae3d66-6982-4c33-a3f4-ca80e0cd9968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,700 training samples\n",
      "1,634 validation samples\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "m9ybm4alx44tp9k0we34n",
    "id": "dD9i6Z2pG-sN"
   },
   "source": [
    "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "cellId": "iwqd3ad1js80vl8i354nnl",
    "id": "XGUqOCtgqGhP"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 164  # указываем батч-сайз\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "66cyrih7c3p0cl88mzgvetq",
    "id": "8bwa6Rts-02-"
   },
   "source": [
    "# 4. Train Our Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "imoti25fzyfya532kf959",
    "id": "3xYQ3iLO08SX"
   },
   "source": [
    "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s06oty1c87j31dvpuqspgj",
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "## 4.1. BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s4gtg8ptifgsq4bdfylkhe",
    "id": "WnQW9E-bBCRt"
   },
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "cellId": "rttscznhild2cfrg0evrue",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "bf9dfa1ff3e642fbb74c5146d21044c2",
      "1c2b0ede959142fc89bf07a9c88df638",
      "1296a3d754b344a482a03e5af84e805e",
      "6f132d7bb83d41b6847df0d0ec0a1b92",
      "2755b9838bae408ca8cf667ad9d501fc",
      "f8874fec8a404ae89a38fd2ecbb357cf",
      "a7bdbedc75de4f77b45f1389c2ea0abc",
      "978c24b18b594eaf8ca47730a88eefb9",
      "fe254c3bcc08402eb506f0e98f5673a7",
      "cea84f9c3db641acb98314028b305514",
      "23ca9359e6c44232a1346e6f2ab7e48c",
      "d689bc8d488a4dc09c393b4fc9747bcb",
      "6c7dec7b1e804c2195f6e60fb3c1d18e",
      "0fe5b1d0540240a8a8426352c24b2887",
      "4b1e27aff6f04fec8268d951e46b1e63",
      "440da34c72344cb08e4a1ee5de7049ee"
     ]
    },
    "id": "gFsCTp_mporB",
    "outputId": "af690f33-6cd5-4678-bdaf-209f068f70f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ee136aeee144e6925ffdf161427f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714355318.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "#НУЖНО УКАЗАТЬ КОЛ-ВО КЛАССОВ\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased\", # Use the 12-layer BERT model, with an uncased vocab.  # Geotrend/bert-base-ru-cased  DeepPavlov/rubert-base-cased\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zwt8dfat1yn93b1dbyv65",
    "id": "e0Jv6c7-HHDW"
   },
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tlfcqv02mm9z73ta5kclm",
    "id": "qRWT-D4U_Pvx"
   },
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vkncfex3bwirec6q7ay3a",
    "id": "8o-VEBobKwHk"
   },
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "cellId": "3q01ima1jp3292ro3a39aq",
    "id": "GLs72DuMODJO"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "cellId": "wcx8dw4f53a7e98jomhwb2",
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4eub57f4047mh1jxx1jn9l",
    "id": "RqfmWwUR_Sox"
   },
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "edt6a10duzijfihsf4ahhr",
    "id": "_QXZhFb4LnV5"
   },
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "u98y155y7cd8cupgb208g",
    "id": "pE5B99H5H2-W"
   },
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "cellId": "pm58rxf5eena1gqat4x3rk",
    "id": "9cQNvaZ9bnyy"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xh2gi91vyzsw4g6h3s7jdi",
    "id": "KNhRtWPXH9C3"
   },
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "cellId": "whbwtueefmf6cyv4kjctb",
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3kyi9m0kxhx5tfm5oswuum",
    "id": "cfNIhN19te3N"
   },
   "source": [
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x3uppw30mm7yhmib1lrdr"
   },
   "source": [
    "#!g1.1\n",
    "Как определить оптимальный батч сайз? и MAX_SEQ_LENGTH?\n",
    "72 и 256?\n",
    "\n",
    "Кажется, что мы сильно порезали наши данные, оценим качество и перезапустим обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "cellId": "8pf7qzfvneap0oeobtn11q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J-FYdx6nFE_",
    "outputId": "b2c3e30b-eb5d-4b13-a207-05a48a87ed2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
      "  Batch    80  of     90.    Elapsed: 0:00:47.\n",
      "\n",
      "  Average training loss: 0.61\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.70\n",
      "  Validation Loss: 0.58\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
      "  Batch    80  of     90.    Elapsed: 0:00:41.\n",
      "\n",
      "  Average training loss: 0.56\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.72\n",
      "  Validation Loss: 0.55\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
      "  Batch    80  of     90.    Elapsed: 0:00:41.\n",
      "\n",
      "  Average training loss: 0.50\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.71\n",
      "  Validation Loss: 0.57\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of     90.    Elapsed: 0:00:20.\n",
      "  Batch    80  of     90.    Elapsed: 0:00:41.\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.73\n",
      "  Validation Loss: 0.56\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:03:20 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ly9tdk1mg6n602zpsp5is",
    "id": "VQTvJ1vRP7u4"
   },
   "source": [
    "Let's view the summary of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "cellId": "lza3rl3svylrocukdly2q",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6O_NbXFGMukX",
    "outputId": "a9e51eda-5eae-4800-87d5-8d016ff25bb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0:00:53</td>\n",
       "      <td>0:00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0:00:46</td>\n",
       "      <td>0:00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.61         0.58           0.70       0:00:53         0:00:04\n",
       "2               0.56         0.55           0.72       0:00:46         0:00:02\n",
       "3               0.50         0.57           0.71       0:00:46         0:00:02\n",
       "4               0.46         0.56           0.73       0:00:46         0:00:02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.см\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yzvfe5g54jdytuny4eajmj",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6O_NbXFGMukX",
    "outputId": "a9e51eda-5eae-4800-87d5-8d016ff25bb2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.см\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "cellId": "yo3hba3sjdcplp76ip3qv",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "68xreA9JAmG5",
    "outputId": "70b8500d-7efc-4c99-de1f-05e8795e6298"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "64wn7tn0vhjavdposdxbwc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "#сохраним веса модели:\n",
    "\n",
    "torch.save(model.state_dict(), 'ru-inappropriate.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "cellId": "48uwyh1wk8jb5o2o5e796m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xbfbht083v8coazqpcs6d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "\n",
    "\n",
    "#загрузим модель\n",
    "\n",
    "#model = TheModelClass(args, *kwargs) \n",
    "model.load_state_dict(torch.load('ru-inappropriate.bin')) \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "c6ihl02zkkd3klrsvlcosb",
    "id": "mkyubuJSOzg3"
   },
   "source": [
    "# 5. Performance On Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6n692yzxdefcoh50koyk",
    "id": "DosV94BYIYxg"
   },
   "source": [
    "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "de3s75v75tom1mpybi35ba",
    "id": "Tg42jJqqM68F"
   },
   "source": [
    "### 5.1. Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "pl9g4lgxyra35b2h2mkdzh",
    "id": "xWe0_JW21MyV"
   },
   "source": [
    "\n",
    "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "cellId": "lautmynmlau4wh8fgnnr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>inappropriate</th>\n",
       "      <th>offline_crime</th>\n",
       "      <th>online_crime</th>\n",
       "      <th>drugs</th>\n",
       "      <th>gambling</th>\n",
       "      <th>pornography</th>\n",
       "      <th>prostitution</th>\n",
       "      <th>slavery</th>\n",
       "      <th>suicide</th>\n",
       "      <th>...</th>\n",
       "      <th>body_shaming</th>\n",
       "      <th>health_shaming</th>\n",
       "      <th>politics</th>\n",
       "      <th>racism</th>\n",
       "      <th>religion</th>\n",
       "      <th>sexual_minorities</th>\n",
       "      <th>sexism</th>\n",
       "      <th>social_injustice</th>\n",
       "      <th>human_labeled</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>если тупой, то хотя бы проверь, насколько ты у...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Из за этого началась война между террористоми ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  inappropriate  \\\n",
       "0  если тупой, то хотя бы проверь, насколько ты у...            1.0   \n",
       "1  Из за этого началась война между террористоми ...            1.0   \n",
       "\n",
       "   offline_crime  online_crime  drugs  gambling  pornography  prostitution  \\\n",
       "0            0.0           0.0    0.0       0.0          0.0           0.0   \n",
       "1            0.0           0.0    0.0       0.0          0.0           0.0   \n",
       "\n",
       "   slavery  suicide  ...  body_shaming  health_shaming  politics  racism  \\\n",
       "0      0.0      0.0  ...           0.0             0.0       0.0     0.0   \n",
       "1      0.0      0.0  ...           0.0             0.0       0.0     0.0   \n",
       "\n",
       "   religion  sexual_minorities  sexism  social_injustice  human_labeled  \\\n",
       "0       0.0                0.0     0.0               0.0              0   \n",
       "1       0.0                0.0     0.0               0.0              1   \n",
       "\n",
       "   labels  \n",
       "0       1  \n",
       "1       1  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "cellId": "x30rn304of6srobb6nbeu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 16,334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = test_df.text.values\n",
    "labels = (test_df.inappropriate > 0.5).astype('int').values\n",
    "\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences.  # max lenght IS SET TO 64!\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 144    #BATCH SIZE!\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "cellId": "xp2zm3cc65iyjtdnmm42k",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hba10sXR7Xi6",
    "outputId": "e35f0a6e-72c5-4bd0-9c4b-dcec9ef5059d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 16,334 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "cellId": "3l42cv34i7g2dlc51nuaw"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "cellId": "bw4wtff0pl1tdg97d106u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16334,), (16334,))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "flat_true_labels.shape, flat_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "cellId": "e06gv21cfxvtcgq89xo0x"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vlquhyszekou6imfwwj5p"
   },
   "source": [
    "## Результаты обучения на deep pavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "r0eqp5swoybutyj75ll419"
   },
   "source": [
    "#!g1.1\n",
    "пример без fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "cellId": "mcjta41w7151xn7qr908m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.799\n",
      "f1 0.75\n",
      "roc_auc 0.85\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(flat_true_labels, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(flat_true_labels, flat_predictions, average='macro'),2)) #качество на тесте\n",
    "print('roc_auc', np.round(roc_auc_score(flat_true_labels, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "pjukqonywkjxu66c3zidya"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(flat_true_labels, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(flat_true_labels, flat_predictions, average='macro'),2)) #качество на тесте\n",
    "print('roc_auc', np.round(roc_auc_score(flat_true_labels, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "cellId": "usd3p7wxc7kiu3m86ajxth"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.799\n",
      "f1 0.75\n",
      "roc_auc 0.85\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(flat_true_labels, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(flat_true_labels, flat_predictions, average='macro'),2)) #качество на тесте\n",
    "print('roc_auc', np.round(roc_auc_score(flat_true_labels, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9oj7vkrj5bux1uo7xj0gmr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "print('roc_auc', np.round(roc_auc_score(y_true, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hb2q4rje87cg5tt4cfur5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(flat_true_labels, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(flat_true_labels, flat_predictions, average='macro'),2)) #качество на тесте\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xlpeiqrxld6j34h8z8l0g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "cellId": "f5075set1ta02lxr3f9ku"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.789\n",
      "f1 0.74\n",
      "roc_auc 0.84\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(y_true, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(y_true, flat_predictions, average='macro'),2)) #качество на тесте\n",
    "print('roc_auc', np.round(roc_auc_score(y_true, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "cellId": "4omuvfrjjjc5uzvwsnr6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     11442\n",
      "           1       0.66      0.61      0.63      4892\n",
      "\n",
      "    accuracy                           0.79     16334\n",
      "   macro avg       0.75      0.74      0.74     16334\n",
      "weighted avg       0.79      0.79      0.79     16334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "#!g1.1\n",
    "print(classification_report(flat_true_labels, flat_predictions)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "cellId": "ip1suvfayjbhcqvp61fn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     11442\n",
      "           1       0.70      0.59      0.64      4892\n",
      "\n",
      "    accuracy                           0.80     16334\n",
      "   macro avg       0.76      0.74      0.75     16334\n",
      "weighted avg       0.79      0.80      0.79     16334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(classification_report(y_true, flat_predictions)) #качество на тесте\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8ycxjhaxazxbdrr3ur7ecr"
   },
   "source": [
    "## Сравним с результатами мультиязычной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "cellId": "sychs2k2ani2mjr9b1x0q2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.781\n",
      "f1 0.72\n",
      "roc_auc 0.83\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "#!g1.1\n",
    "print('accuracy', np.round(accuracy_score(y_true, flat_predictions),3)) #качество на тесте\n",
    "print('f1', np.round(f1_score(y_true, flat_predictions, average='macro'),2)) #качество на тесте\n",
    "print('roc_auc', np.round(roc_auc_score(y_true, np.concatenate(predictions, axis=0)[:, 1]),2)) #качество на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "cellId": "75aj2ej031l9uexvdoiy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     11442\n",
      "           1       0.66      0.55      0.60      4892\n",
      "\n",
      "    accuracy                           0.78     16334\n",
      "   macro avg       0.74      0.71      0.72     16334\n",
      "weighted avg       0.77      0.78      0.77     16334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(classification_report(y_true, flat_predictions)) #качество на тесте\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "0hc1dtb3g1984uzcus855x9"
   },
   "outputs": [],
   "source": [
    "## Вывод\n",
    "\n",
    "мы обучили две модели на одном русскоязычном датасете для бинарной классификации\n",
    "\n",
    "Мы видим, что моноязычная модель \"из коробки\" работает чуть лучше, чем мультиязычная модель. \n",
    "Насколько важна разница в несколько пунктов - зависит от задачи, тем не менее, стоит так же провести сравнение с моделью с полным мультиязычным словарем и \n",
    "сравнить результат \n",
    "\n",
    "\n",
    "Предметом нашего исследования является - поиск - есть ли разница в уязвимости моделей для адверсариальных атак в\n",
    "зависимости от того, модель моно или мультиязычная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zi676fbza5vgv4argg8nr"
   },
   "source": [
    "## Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "cellId": "6w0mi4p25niziqm4xcvgn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from textattack.transformations import WordSwapEmbedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "g3dp5wguqvmpw10c8ekhvf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "from textattack.shared import AbstractWordEmbedding, WordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "cellId": "x8pxps0csuhi742j0tai7n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "cellId": "nj6mq0ngntsa7zw2dl4fcg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textattack.shared.word_embeddings.py'; 'textattack.shared.word_embeddings' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-518045089368>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtextattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGensimWordEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'textattack.shared.word_embeddings.py'; 'textattack.shared.word_embeddings' is not a package"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from textattack.shared.word_embeddings.py import GensimWordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "cellId": "bs0oa31yb86u4zrlz2bye"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# попробуем переписать textfooler\n",
    "\n",
    "# GensimWordEmbedding\n",
    "\n",
    "from textattack import Attack\n",
    "from textattack.constraints.grammaticality import PartOfSpeech\n",
    "from textattack.constraints.pre_transformation import (\n",
    "    InputColumnModification,\n",
    "    RepeatModification,\n",
    "    StopwordModification,\n",
    ")\n",
    "from textattack.constraints.semantics import WordEmbeddingDistance\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "from textattack.goal_functions import UntargetedClassification\n",
    "from textattack.search_methods import GreedyWordSwapWIR\n",
    "from textattack.transformations import WordSwapEmbedding\n",
    "\n",
    "from textattack.attack_recipes.attack_recipe import AttackRecipe\n",
    "\n",
    "\n",
    "class TextFooler2021Ru(AttackRecipe):\n",
    "\n",
    "    @staticmethod\n",
    "    def build(model_wrapper):\n",
    "        #\n",
    "        # Swap words with their 50 closest embedding nearest-neighbors.\n",
    "        # Embedding: Counter-fitted PARAGRAM-SL999 vectors.\n",
    "        #\n",
    "        transformation = WordSwapEmbedding(embedding = GensimWordEmbedding, max_candidates=50)\n",
    "        #\n",
    "        # Don't modify the same word twice or the stopwords defined\n",
    "        # in the TextFooler public implementation.\n",
    "        #\n",
    "        # fmt: off\n",
    "        stopwords = set(\n",
    "            ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', \n",
    "             'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', \n",
    "             'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда',\n",
    "             'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', \n",
    "             'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей',\n",
    "             'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', \n",
    "             'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', \n",
    "             'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', \n",
    "             'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда',\n",
    "             'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через',\n",
    "             'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', \n",
    "             'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n",
    "        )\n",
    "        # fmt: on\n",
    "        constraints = [RepeatModification(), StopwordModification(stopwords=stopwords)]\n",
    "        #\n",
    "        # During entailment, we should only edit the hypothesis - keep the premise\n",
    "        # the same.\n",
    "        #\n",
    "        input_column_modification = InputColumnModification(\n",
    "            [\"premise\", \"hypothesis\"], {\"premise\"}\n",
    "        )\n",
    "        constraints.append(input_column_modification)\n",
    "        # Minimum word embedding cosine similarity of 0.5.\n",
    "        # (The paper claims 0.7, but analysis of the released code and some empirical\n",
    "        # results show that it's 0.5.)\n",
    "        #\n",
    "        constraints.append(WordEmbeddingDistance(min_cos_sim=0.5))\n",
    "        #\n",
    "        # Only replace words with the same part of speech (or nouns with verbs)\n",
    "        #\n",
    "        constraints.append(PartOfSpeech(allow_verb_noun_swap=True))\n",
    "        #\n",
    "        # Universal Sentence Encoder with a minimum angular similarity of ε = 0.5.\n",
    "        #\n",
    "        # In the TextFooler code, they forget to divide the angle between the two\n",
    "        # embeddings by pi. So if the original threshold was that 1 - sim >= 0.5, the\n",
    "        # new threshold is 1 - (0.5) / pi = 0.840845057\n",
    "        #\n",
    "        use_constraint = UniversalSentenceEncoder(\n",
    "            threshold=0.840845057,\n",
    "            metric=\"angular\",\n",
    "            compare_against_original=False,\n",
    "            window_size=15,\n",
    "            skip_text_shorter_than_window=True,\n",
    "        )\n",
    "        constraints.append(use_constraint)\n",
    "        #\n",
    "        # Goal is untargeted classification\n",
    "        #\n",
    "        goal_function = UntargetedClassification(model_wrapper)\n",
    "        #\n",
    "        # Greedily swap words with \"Word Importance Ranking\".\n",
    "        #\n",
    "        search_method = GreedyWordSwapWIR(wir_method=\"delete\")\n",
    "\n",
    "        return Attack(goal_function, constraints, transformation, search_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "cellId": "ixbe45vs3sk1n1a0ejww"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.TextFooler2021Ru"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "TextFooler2021Ru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "cellId": "qpzm8g62otrvteikl3g4in"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GensimWordEmbedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-700d92bc8552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mattack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFooler2021Ru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-aa5d43012fed>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(model_wrapper)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Embedding: Counter-fitted PARAGRAM-SL999 vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mtransformation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordSwapEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGensimWordEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_candidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Don't modify the same word twice or the stopwords defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GensimWordEmbedding' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "attack = TextFooler2021Ru.build(model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "shxxo6gv9vf7a2y5k4988i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "eg2em6o8p9f4duxu1qhvsp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "Главное - чтобы атаки заработали для русского языка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "cellId": "z8uumzggpybkhsx79xnp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "# обернем атаку\n",
    "\n",
    "import textattack\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "model_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(model, tokenizer)\n",
    "attack = textattack.attack_recipes.PWWSRen2019.build(model_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "cellId": "zwjz0jcwmnhxcagiff6dbb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "attack.transformation.language = \"rus\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "cellId": "seoahvu0pa9e330lha0tzm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "test_df['labels'] = (test_df.inappropriate > 0.5).astype('int').values\n",
    "\n",
    "dataset = Dataset.from_pandas(test_df.sample(1000)[['text', 'labels']])\n",
    "\n",
    "dataset = textattack.datasets.HuggingFaceDataset(dataset, dataset_columns = (['text'], 'labels'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "cellId": "tlpxincw9kg6pndrjmde3i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['скажи свое имя NUMBER раз попей воды поползай под столом и под твоей подушкой будет АЙФОН а там твой номер']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(test_df[test_df.text.str.contains('АЙФОН')].text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "cellId": "y93bvwb71jg94773wwy9t"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "attack_args = textattack.AttackArgs(num_examples=100, log_to_csv=\"logRu11.csv\", checkpoint_interval=20, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "cellId": "ea2dap98irt1qe4i2jel8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "#!g1.1\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "\n",
    "\n",
    "# что на вход можно подавать в качестве аргумента для датасета? туториал подсказывает, что нужно сначала загрузить датасет в библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "s2o34unmfr9us5oe8q1vpb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "#!g1.1\n",
    "%%time \n",
    "\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mvt7uxvtj3ftt4j4p85qzg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "вместо атак для русского языка - мультиязычные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "m1bn334lf6p16wm5hizxok"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "#попробуем PWWSRen2019 рецепт\n",
    "# Create the recipe: PWWS uses a WordNet transformation.\n",
    "recipe = PWWSRen2019.build(model_wrapper)\n",
    "#\n",
    "# WordNet defaults to english. Set the default language to French ('fra')\n",
    "#\n",
    "# See \"Building a free French wordnet from multilingual resources\",\n",
    "# E. L. R. A. (ELRA) (ed.),\n",
    "# Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).\n",
    "recipe.transformation.language = 'rus'\n",
    "\n",
    "\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "cellId": "u70sc19gud49zxigkoi8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapEmbedding(\n",
      "    (max_candidates):  50\n",
      "    (embedding):  WordEmbedding\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): WordEmbeddingDistance(\n",
      "        (embedding):  WordEmbedding\n",
      "        (min_cos_sim):  0.5\n",
      "        (cased):  False\n",
      "        (include_unknown_words):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): UniversalSentenceEncoder(\n",
      "        (metric):  angular\n",
      "        (threshold):  0.840845057\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  False\n",
      "      )\n",
      "    (3): RepeatModification\n",
      "    (4): StopwordModification\n",
      "    (5): InputColumnModification(\n",
      "        (matching_column_labels):  ['premise', 'hypothesis']\n",
      "        (columns_to_ignore):  {'premise'}\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 7      |\n",
      "| Number of failed attacks:     | 70     |\n",
      "| Number of skipped attacks:    | 23     |\n",
      "| Original accuracy:            | 77.0%  |\n",
      "| Accuracy under attack:        | 70.0%  |\n",
      "| Attack success rate:          | 9.09%  |\n",
      "| Average perturbed word %:     | 11.67% |\n",
      "| Average num. words per input: | 17.64  |\n",
      "| Avg num queries:              | 31.79  |\n",
      "+-------------------------------+--------+\n",
      "CPU times: user 23.7 s, sys: 9.98 s, total: 33.7 s\n",
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Logging to CSV at path logRu11.csv\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 15 / 3 / 20:  20%|██        | 20/100 [00:07<00:30,  2.64it/s]textattack: Saving checkpoint under \"checkpoints/1640548459003.ta.chkpt\" at 2021-12-26 19:54:19 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 30 / 7 / 40:  40%|████      | 40/100 [00:13<00:20,  2.92it/s]textattack: Saving checkpoint under \"checkpoints/1640548465111.ta.chkpt\" at 2021-12-26 19:54:25 after 40 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 42 / 15 / 60:  60%|██████    | 60/100 [00:17<00:11,  3.47it/s]textattack: Saving checkpoint under \"checkpoints/1640548468721.ta.chkpt\" at 2021-12-26 19:54:28 after 60 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 56 / 20 / 80:  80%|████████  | 80/100 [00:24<00:06,  3.32it/s]textattack: Saving checkpoint under \"checkpoints/1640548475497.ta.chkpt\" at 2021-12-26 19:54:35 after 80 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 70 / 23 / 100: 100%|██████████| 100/100 [00:31<00:00,  3.13it/s]textattack: Saving checkpoint under \"checkpoints/1640548483313.ta.chkpt\" at 2021-12-26 19:54:43 after 100 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 70 / 23 / 100: 100%|██████████| 100/100 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c5853590>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d51d6e10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f04f0a23f90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fcfaa7d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0690086a90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f069a497b90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f03fbbb2410>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f032ddc3190>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e155f450>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f9d79c10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f87d1cd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f048c3d5610>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f03fb80cf50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fd0de4d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f048c506c90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fbcc83d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c4546c50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fe94bc90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f4daf5d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f963fd10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f06ece36890>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f4daf110>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c5c35a50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06c5c35590>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c5c35250>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d51ebe10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c5c35110>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03f963f790>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e014e950>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e014e810>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e07ffe50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e07ff1d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e07ff290>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fb1ed250>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069c2f0210>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e0701cd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e0701b10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069bc05e50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f048c115f10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f032ddc37d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d4974dd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06d4974e90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06d4974950>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d4974ad0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f048c1156d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06c492ef50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f048c115cd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e014eb50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f032de2a6d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f03fd3bd510>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f032de2a5d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069c2f0050>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069b1a6890>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06c43a0650>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06c43a01d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c41eab10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c41eaad0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e07ffd90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e07ffad0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e07ffcd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e07ffc10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d47cfd90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069b89fd50>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d5738fd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06d5738690>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06d5738c90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069af29ed0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e07ff5d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e0701590>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069c2f0110>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e0701250>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e0701550>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06e0701310>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069af29450>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e07016d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069af29090>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069a5b0350>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f06d445c1d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d4974e10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f069bc05e90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f06e0701450>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f06d445c490>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06ec422490>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f06c43a0710>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069c2f02d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f032de2acd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069bc36150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069b89a150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06ec422f10>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069a49bfd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069a49ba10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f069a49b690>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f069a49bf90>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f069a49bed0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e0701090>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06d5738990>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06e0701150>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06c5a34990>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f069c2f0fd0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f06ec422510>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%%time \n",
    "\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "o31b53cf3b8do108muq5"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%%time \n",
    "\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qd9zjass6va8wk45qxzmot"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "Как мы видим - есть большая волатильность результатов атак и модели в зависимости от разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "3vzg5q8o3xk1dy0drdmw0q"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "что мы сделали - взяли дообученную модель Берта для классификации\n",
    "модель - моноязычная (русская)\n",
    "текст - русский\n",
    "атака - textfooler\n",
    "\n",
    "результат - \n",
    "\n",
    "как адаптировать textfooler  на русский - RusVectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rvzc54ju1hi17zld6kf3lri"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "пришло время понять -как адаптировать рецепт под русский язык!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tuvioy556kmfndes9iri"
   },
   "source": [
    "#!g1.1\n",
    "## Все вместе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "cellId": "7m1k6c1t91jgurxzo2sbx"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd42a642d4bb43dfaed5648d1c9522e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483e7d9068f94bc9bd8d539d994614a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86da215eb7a4092b26af3df208df596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be55c59b9dfe460c8a0ad18132634c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb2a29b916f4590999b4166575c10c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  delete\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  WordSwapMaskedLM(\n",
      "    (method):  bae\n",
      "    (masked_lm_name):  BertForMaskedLM\n",
      "    (max_length):  512\n",
      "    (max_candidates):  50\n",
      "    (min_confidence):  0.0\n",
      "  )\n",
      "  (constraints): \n",
      "    (0): PartOfSpeech(\n",
      "        (tagger_type):  nltk\n",
      "        (tagset):  universal\n",
      "        (allow_verb_noun_swap):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): UniversalSentenceEncoder(\n",
      "        (metric):  cosine\n",
      "        (threshold):  0.936338023\n",
      "        (window_size):  15\n",
      "        (skip_text_shorter_than_window):  True\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (2): RepeatModification\n",
      "    (3): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n",
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 52     |\n",
      "| Number of failed attacks:     | 5      |\n",
      "| Number of skipped attacks:    | 43     |\n",
      "| Original accuracy:            | 57.0%  |\n",
      "| Accuracy under attack:        | 5.0%   |\n",
      "| Attack success rate:          | 91.23% |\n",
      "| Average perturbed word %:     | 10.97% |\n",
      "| Average num. words per input: | 18.48  |\n",
      "| Avg num queries:              | 102.89 |\n",
      "+-------------------------------+--------+\n",
      "CPU times: user 1min 26s, sys: 27.3 s, total: 1min 53s\n",
      "Wall time: 2min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
      "textattack: Logging to CSV at path logRu2.csv\n",
      "[Succeeded / Failed / Skipped / Total] 11 / 1 / 8 / 20:  20%|██        | 20/100 [00:26<01:44,  1.30s/it]textattack: Saving checkpoint under \"checkpoints/1640382606345.ta.chkpt\" at 2021-12-24 21:50:06 after 20 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 22 / 2 / 16 / 40:  40%|████      | 40/100 [00:44<01:06,  1.10s/it]textattack: Saving checkpoint under \"checkpoints/1640382624516.ta.chkpt\" at 2021-12-24 21:50:24 after 40 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 32 / 3 / 25 / 60:  60%|██████    | 60/100 [00:59<00:39,  1.01it/s]textattack: Saving checkpoint under \"checkpoints/1640382639692.ta.chkpt\" at 2021-12-24 21:50:39 after 60 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 42 / 4 / 34 / 80:  80%|████████  | 80/100 [01:23<00:20,  1.05s/it]textattack: Saving checkpoint under \"checkpoints/1640382664131.ta.chkpt\" at 2021-12-24 21:51:04 after 80 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 52 / 5 / 43 / 100: 100%|██████████| 100/100 [01:37<00:00,  1.03it/s]textattack: Saving checkpoint under \"checkpoints/1640382677804.ta.chkpt\" at 2021-12-24 21:51:17 after 100 attacks.\n",
      "[Succeeded / Failed / Skipped / Total] 52 / 5 / 43 / 100: 100%|██████████| 100/100 [01:37<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f2568d51e50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb04bbed0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb04f9950>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1b71728e50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f233c4be190>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f23b7410710>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f233d431e50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f233d341190>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f25823dfc90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fe1f8e210>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f234ed3ac90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f200438e090>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f25690e6b50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f234b654290>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f25828bf390>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f255e71c6d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f23b87a3f50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1b71728550>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb0570d10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f25ae4e7f10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb0404fd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1f900a4ed0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1f900a4e90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1f900a4050>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1b7170cc90>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f25824f4110>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f2004399210>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f234b654210>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fe1bfbf10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f25ae4d36d0>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f25828bf190>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1f900af850>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f23b851a650>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb055fe50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb05704d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f234b6542d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb868fb10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1b71746210>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f255e71cb10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1d18710>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb041b650>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1d55850>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1d18d90>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fe1d18910>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f1cb86a00d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb86a0950>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb86a0190>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb86a0590>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1b7170cc10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1b7170cbd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f23b73c1610>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1bc17b9e50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1cb86bb110>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f2581ff0a50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb86bb490>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fba347f50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fba2e9ad0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fba2e9510>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f20043a85d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fba2f3990>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f1bc17c8950>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb00d9cd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f234b666cd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1f97dd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb007ebd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1ca7335a50>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1ca7335890>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1ca7335ad0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1ca7335210>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1ca7335d50>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f2580f68350>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1bc17d2a10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fe1f97ed0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1c78c3e110>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1cb8697850>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1bf58d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1f900a4e10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1cb8697810>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb8697890>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f2580f68810>,\n",
       " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f1fb04f9250>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1f900a4c10>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1f900a4790>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1f900a4f10>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1f900a4dd0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fe1bf57d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1cef721050>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cef7217d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1bf5150>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1b7170c7d0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1c78c3e3d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f25837d5810>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb038f750>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb038fed0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f2580f68210>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1cb8697fd0>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fe1faa510>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb05115d0>,\n",
       " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f1fb0511990>,\n",
       " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f1fb04f9550>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "%%time\n",
    "\n",
    "#!g1.1\n",
    "## Попробуем BAE еще раз\n",
    "#attack_recipes.bae_garg_2019.BAEGarg2019\n",
    "attack = textattack.attack_recipes.bae_garg_2019.BAEGarg2019.build(model_wrapper)\n",
    "attack_args = textattack.AttackArgs(num_examples=100, log_to_csv=\"logRu2.csv\", checkpoint_interval=20, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xgh4cxhql6ngvu4u7uaia"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "с учетом того, что у моделей разные словари - нужно понять, как адаптировать для русского?\n",
    "посмотреть примеры для других языков из репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "52zcclhu6f78phaw31mwiv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "Пока что видно, что бае справляется - нужно смотреть на примеры"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT Fine-Tuning Sentence Classification v4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Yandex DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "e9629809-34ce-453f-9ee4-0c3966339c97",
  "notebookPath": "text_attacks/notebooks/russian-inappropriate-messages.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fe5b1d0540240a8a8426352c24b2887": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1058e0b5baa248faa60c1ad146d10bf7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1296a3d754b344a482a03e5af84e805e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8874fec8a404ae89a38fd2ecbb357cf",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2755b9838bae408ca8cf667ad9d501fc",
      "value": 433
     }
    },
    "1c2b0ede959142fc89bf07a9c88df638": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ca9359e6c44232a1346e6f2ab7e48c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fe5b1d0540240a8a8426352c24b2887",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6c7dec7b1e804c2195f6e60fb3c1d18e",
      "value": 440473133
     }
    },
    "2755b9838bae408ca8cf667ad9d501fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "375cc635389c4ddb9bf2aa443df58bae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "440da34c72344cb08e4a1ee5de7049ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472198d5b6a748b3a81f9364fd1fa711": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b1e27aff6f04fec8268d951e46b1e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c7dec7b1e804c2195f6e60fb3c1d18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6f132d7bb83d41b6847df0d0ec0a1b92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_978c24b18b594eaf8ca47730a88eefb9",
      "placeholder": "​",
      "style": "IPY_MODEL_a7bdbedc75de4f77b45f1389c2ea0abc",
      "value": " 433/433 [00:00&lt;00:00, 2.02kB/s]"
     }
    },
    "82ddfcea0e4c4e5a86cf6eca8585be8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8c76faadf2f4415393c6f0a805f0d72b",
       "IPY_MODEL_e0bb735fda99434a90380e7fc664212d"
      ],
      "layout": "IPY_MODEL_8a256ba4a19e4ec98fe3c3c99fba4daa"
     }
    },
    "8a256ba4a19e4ec98fe3c3c99fba4daa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c76faadf2f4415393c6f0a805f0d72b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1058e0b5baa248faa60c1ad146d10bf7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdb78e75309f4bc09366533331e72431",
      "value": 231508
     }
    },
    "978c24b18b594eaf8ca47730a88eefb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7bdbedc75de4f77b45f1389c2ea0abc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf9dfa1ff3e642fbb74c5146d21044c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1296a3d754b344a482a03e5af84e805e",
       "IPY_MODEL_6f132d7bb83d41b6847df0d0ec0a1b92"
      ],
      "layout": "IPY_MODEL_1c2b0ede959142fc89bf07a9c88df638"
     }
    },
    "cdb78e75309f4bc09366533331e72431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cea84f9c3db641acb98314028b305514": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d689bc8d488a4dc09c393b4fc9747bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_440da34c72344cb08e4a1ee5de7049ee",
      "placeholder": "​",
      "style": "IPY_MODEL_4b1e27aff6f04fec8268d951e46b1e63",
      "value": " 440M/440M [00:07&lt;00:00, 55.5MB/s]"
     }
    },
    "e0bb735fda99434a90380e7fc664212d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_472198d5b6a748b3a81f9364fd1fa711",
      "placeholder": "​",
      "style": "IPY_MODEL_375cc635389c4ddb9bf2aa443df58bae",
      "value": " 232k/232k [00:00&lt;00:00, 616kB/s]"
     }
    },
    "f8874fec8a404ae89a38fd2ecbb357cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe254c3bcc08402eb506f0e98f5673a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23ca9359e6c44232a1346e6f2ab7e48c",
       "IPY_MODEL_d689bc8d488a4dc09c393b4fc9747bcb"
      ],
      "layout": "IPY_MODEL_cea84f9c3db641acb98314028b305514"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
